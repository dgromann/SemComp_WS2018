{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dgromann/SemComp_WS2018/blob/master/Tutorial2/Tutorial2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "USq3Q7aNESPZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Lesson 0.0.0: Store this notebook! \n",
        "\n",
        "Go to \"File\" and make sure you store this file as a local copy to either GitHub or your Google Drive. If you do not have a Google account and also do not want to create one, please check Option C below. \n"
      ]
    },
    {
      "metadata": {
        "id": "w3feppwJEZlH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Option A)  Google Drive WITH collaboration \n",
        "\n",
        "\n",
        "If you want to work in a **collaborative** manner where each of you in the group can see each other's contributions, one of you needs to store the notebook in **Google Drive** and share it with the others. You share it by clicking on the **SHARE** button on the top right of this page and share the link with the \"everyone who receives this link can edit\" option with the other team members per e-mail, skype, or any other way you prefer. \n",
        "\n",
        "If you work with others, keep in mind to always copy the code before you edit it and always indicate your name as a comment (e.g. #Dagmar ) in the cell that it is clear who wrote which part. I also recommend creating a new code cell for your contributions.  "
      ]
    },
    {
      "metadata": {
        "id": "ThoArFGwEfbV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Option B) Github without collaboration\n",
        "\n",
        "\n",
        "Collaborative functions are **not available** when storing the notebook in **GitHub**; you will see your own work but not that of others. "
      ]
    },
    {
      "metadata": {
        "id": "3JZ5XKBjEjNk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Option C) Download this notebook as ipynb (Jupyter notebook) or py (Python file)\n",
        "\n",
        "To run either of these on your local machine requires the installation of the required programs, which for the first tutorial are Python and NLTK. This will become more as we continue on to machine learning (requiring sklearn) and deep learning (requiring tensorflow and/or pytorch). In Google Codelab all of these are provided and do not need to be installed locally. "
      ]
    },
    {
      "metadata": {
        "id": "7C5zjRSUGiS0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lesson 0.0: Let's import the libaries to Python that we need today"
      ]
    },
    {
      "metadata": {
        "id": "gWre-ailGh0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('gutenberg')\n",
        "              \n",
        "# Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Part-of-Speech tagger\n",
        "from nltk.tag.perceptron import PerceptronTagger\n",
        "# WordNet\n",
        "from nltk.corpus import wordnet as wn\n",
        "# Gutenberg corpus we need for Lesson 3\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "# Lemmatizer \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Stemmer \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sz7WutteEpYP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lesson 1: Tokenization and Part-of-Speech (POS) tagging\n",
        "\n",
        "What is the difference in pronunciation, POS tag, and meaning? Use WordNet to retrieve different senses of the word."
      ]
    },
    {
      "metadata": {
        "id": "kWk1T0_vElQd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tagger = PerceptronTagger()\n",
        "\n",
        "# Exercise: Tokenize and Part-of-Speech (POS) tag the following sentence\n",
        "# Use the already initialized tagger \n",
        "sentence = \"It just tears me apart to see you suffering like that and in tears.\"\n",
        "\n",
        "# Exercise: Use WordNet to retrieve the different senses of the word \"tears\"\n",
        "# What is the difference in pronunciation, POS tag, and meaning? (determine in\n",
        "# discussion, not automatically)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BR6TMEG_HkqK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lesson 2: Lemmatizing and Stemming \n",
        "\n",
        "We have looked at the comparison between these two in the lecture. Now it is time for you to play around \n",
        "with the two yourself.\n",
        "\n",
        "Which stemmer worked better? Which method would you prefer to determine word frequency\n",
        "information of a text corpus?"
      ]
    },
    {
      "metadata": {
        "id": "i8KIF9ePHyLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Selection of stemmers \n",
        "ps = PorterStemmer()\n",
        "ls = LancasterStemmer()\n",
        "ss = SnowballStemmer(\"english\")\n",
        "\n",
        "# Exercise: Lemmatize and stem (maybe try different stemmers) the following words\n",
        "words = ['presumably', 'provisions', 'owed', 'abacus', 'flies', 'dies', 'mules',\n",
        "        'seizing', 'caresses', 'sensational', 'colonizer', 'traditional', 'plotted']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSCIVYBkIumf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lesson 3: Apply methods to a whole text\n",
        "\n",
        "From the Gutenberg corpus in NLTK, we will use the Shakespear text \"Macbeth\" that has already been imported above. "
      ]
    },
    {
      "metadata": {
        "id": "UupGWDCuI0Jo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = gutenberg.words(\"shakespeare-macbeth.txt\")\n",
        "\n",
        "# Exercise: Print out the number words in the text.\n",
        "print(\"The Gutenberg Shakespeare text has \", yourVariable, \" words.\")\n",
        "\n",
        "# Exercise: Print out the number of unique words in the text (set vs. list)\n",
        "\n",
        "# Exercise: Lowercase all words and remove punctuation and numbers\n",
        "\n",
        "# Exercise: Lemmatize the result of b), keep only unique lemmas, and print the result.\n",
        "\n",
        "# Exercise: Stem the results of b), keep only unique stems, and print the result.\n",
        "#  Compare the count of of lemmas and stems. What can you observe?\n",
        "\n",
        "# Exercise: Create a list of words that are in WordNet from the lemma list. \n",
        "# What kind of words are kept and which ones not?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qGOAqUuNLio9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lesson 4: Levenshtein distance \n",
        "\n",
        "Try to implement the Levenshtein edit distance yourself. Here a brief example of what it was: \n",
        "\n",
        "* If s is \"test\" and t is \"test\", then LD(s,t) = 0, because no transformations are needed. The strings are already identical.\n",
        "* If s is \"test\" and t is \"tent\", then LD(s,t) = 1, because one substitution (change \"s\" to \"n\") is sufficient to transform s into t. \n",
        "\n",
        "The steps that are needed for the algorithm to work are: \n",
        "\n",
        "\n",
        "1.   Set n to be the length of string1. Set m to be the length of string2. If n=0, return m and exit. If m = 0, return n and exit.\n",
        "2.   Create a matrix containing 0 to m rows and 0 to n columns. Initialize the first row to 0 to n and the first colum to 0 to m. Our        string1 should be the longer string for this algorithm to work, so we need to check the length and replace the two strings if \n",
        "       necessary. String1 is written to column 0 and string2 to row 0. \n",
        "3.   Start in cell matrix[0,0] and compare the first row element with the first column element - they are both \"Null\", so we write   \n",
        "       zero into the cell matrix[0,0]\n",
        "4.   Go to the next cell matrix[1,1] and compare the chacaters. There are two options here: \n",
        "       a) the characters are identical: copy the diagonal element to the left \n",
        "       b) the characters are not identical: take the minimum value of the three cells diagonal left, left element, or element above \n",
        "       and add 1 to it \n",
        "5.   Iterate over the whole matrix repeating step 4\n",
        "6.   Return the last diagonal element that corresponds to the edit distance\n"
      ]
    },
    {
      "metadata": {
        "id": "VQNm0U-NItIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Exercise: upload the Levenshtein test file from the tutorial2 folder on \n",
        "# github and use it to test your implementation of the algorithm below\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5SAxLNNjGyKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Exercise: try to write your own version of the algorithm described \n",
        "# in the text cell above\n",
        "\n",
        "def levenshtein(string1, string2): \n",
        "  if len(string1) < len(string2): \n",
        "    return levenshtein(string2, string1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}